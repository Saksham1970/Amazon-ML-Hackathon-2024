{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc54f18-1a09-4f88-a70d-15d5524ecc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, Idefics2ForConditionalGeneration\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68b0d13-4d2c-40ba-be1f-7b689b1c564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH = \"./models/trained/train/checkpoint-1625\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a97c8d-f0ca-4d2e-91b5-9324a5d3b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chat templates should be in a 'chat_template.json' file but found key='chat_template' in the processor's config. Make sure to move your template to its own file.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"HuggingFaceM4/idefics2-8b\",\n",
    "    do_image_splitting=False,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "model = Idefics2ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=DEVICE\n",
    ")\n",
    "\n",
    "model.enable_adapters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e071c66-1410-4494-ac99-56e472761ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 90666/90666 [01:00<00:00, 1509.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        return (image_path, Image.open(image_path).convert('RGB'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_images_concurrently(folder_path, max_workers=8):\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    images = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Wrap the executor.map with tqdm for progress bar\n",
    "        for result in tqdm.tqdm(executor.map(load_image, image_paths), total=len(image_paths), desc=\"Loading images\"):\n",
    "            images[result[0]] = result[1]\n",
    "    return images\n",
    "    \n",
    "images_dict = process_images_concurrently(\"./processed/test\", max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f76ba311-5d43-428a-ad0f-85a3d3d8d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global images_dict\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(\"./processed/test\", os.path.basename(row['image_link']))\n",
    "        image = images_dict[image_path]\n",
    "        return {\n",
    "            'image': image,\n",
    "            'entity_name': row['entity_name'],\n",
    "            'id': idx\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96884d1c-95c8-492b-a6a1-6a246ec6051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc593f53-93f0-4fd7-b7ac-67b2f7cb1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images_ = [item['image'] for item in batch]\n",
    "    entity_names = [item['entity_name'] for item in batch]\n",
    "    ids = [item['id'] for item in batch]\n",
    "    \n",
    "    questions = [f'What is the {name.replace(\"_\", \" \")} of the product?' for name in entity_names]\n",
    "    \n",
    "    system_prompts = [f\"\"\"\n",
    "    1. Report the value and unit exactly as they appear in the image.\n",
    "    2. If the feature is not visible respond with an empty string.\n",
    "    3. Provide your answer in the format: \"value unit\" (e.g., \"500 gram\" or \"2.5 inch\").\n",
    "    4. Acceptable units: {entity_unit_map[name]}\n",
    "    \"\"\" for name in entity_names]\n",
    "    \n",
    "    texts = []\n",
    "    images = []\n",
    "    for system_prompt, question, image in zip(system_prompts, questions, images_):\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {'type': 'text', 'text': system_prompt},\n",
    "                    {'type': 'image'},\n",
    "                    {'type': 'text', 'text': question}\n",
    "                ]\n",
    "            }     \n",
    "        ]\n",
    "        text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        texts.append(text.strip())\n",
    "        images.append([image])\n",
    "\n",
    "    inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    return inputs, entity_names, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b0018d-6418-4a89-9e9e-a8ef10d1abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model, dataloader):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for batch, entity_names, ids in tqdm.tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                **batch,\n",
    "                max_new_tokens=30,\n",
    "                )\n",
    "            \n",
    "            generated_texts = processor.batch_decode(generated_ids[:, batch[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
    "            op = [{'id': id_, 'entity_name': entity_name, 'generated_text': generated_text} for id_,entity_name, generated_text in zip(ids, entity_names, generated_texts)]\n",
    "            results.extend(op)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f76c187-d43b-4275-935a-18009be751ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/test.csv')\n",
    "BATCH_SIZE = 65  \n",
    "NUM_WORKERS = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ec0009-c80b-47c2-aa96-04b62769f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b171d43-50ca-4e61-bad3-e17a0b8de38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 462/462 [1:55:28<00:00, 15.00s/it]\n"
     ]
    }
   ],
   "source": [
    "results = generate_responses(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4265bfa0-396e-4f31-980d-ed9a25ecb744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Results saved to 'inference_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('inference_results.csv', index=False)\n",
    "print(\"Inference completed. Results saved to 'inference_results.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
