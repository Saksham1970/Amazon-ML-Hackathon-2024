{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03783d6e-759c-4295-9314-66ab5e4ed2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, Idefics2ForConditionalGeneration\n",
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac360209-ab3e-4658-a006-3171fbb9a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chat templates should be in a 'chat_template.json' file but found key='chat_template' in the processor's config. Make sure to move your template to its own file.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"HuggingFaceM4/idefics2-8b\",\n",
    "    do_image_splitting=False\n",
    ")\n",
    "\n",
    "model = Idefics2ForConditionalGeneration.from_pretrained(\n",
    "    \"./models/trained/train/checkpoint-250\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules='.*(text_model|modality_projection|perceiver_resampler).*(down_proj|gate_proj|up_proj|k_proj|q_proj|v_proj|o_proj).*$',\n",
    "        use_dora=False,\n",
    "        init_lora_weights=\"gaussian\"\n",
    ")\n",
    "\n",
    "# model.add_adapter(lora_config)\n",
    "model.enable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68571794-82a4-44f3-978f-a04d335cd8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
      "/tmp/ipykernel_116801/1423392390.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "test_df = pd.read_csv('./dataset/test.csv')\n",
    "req = test_df['entity_name'].value_counts()\n",
    "req = (req * (150000/len(test_df))).astype(int) - train_df['entity_name'][:20000].value_counts()\n",
    "req = req + [682, 682, 682, 682, -7*682, 682, 682, 682]\n",
    "\n",
    "sampled_df_list = []\n",
    "\n",
    "for entity, count in req.items():\n",
    "    # Sample from each entity\n",
    "    entity_df = train_df.iloc[20000:][train_df['entity_name'] == entity]\n",
    "    sampled_entity_df = entity_df.sample(n=count, random_state=42)  # Use random_state for reproducibility\n",
    "    sampled_df_list.append(sampled_entity_df)\n",
    "\n",
    "# Concatenate all sampled dataframes\n",
    "train_df = pd.concat(sampled_df_list)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0ab008-57b5-4afd-be70-cc3a59021976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 255887/255887 [02:55<00:00, 1456.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        return (image_path, Image.open(image_path).convert('RGB'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_images_concurrently(folder_path, max_workers=8):\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    images = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Wrap the executor.map with tqdm for progress bar\n",
    "        for result in tqdm.tqdm(executor.map(load_image, image_paths), total=len(image_paths), desc=\"Loading images\"):\n",
    "            images[result[0]] = result[1]\n",
    "    return images\n",
    "    \n",
    "images_dict = process_images_concurrently(\"./processed/train\", max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d8a417-a970-4d52-8194-5930acf845eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names = [os.path.basename(x) for x in train_df['image_link']]\n",
    "correct_images = set(os.listdir(\"./processed/train\"))\n",
    "images_names = [f\"./processed/train/{x}\" if x in correct_images else None for x in images_names]\n",
    "train_df['image'] = images_names\n",
    "train_df = train_df.dropna()\n",
    "data_dict = train_df.to_dict('list')\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "train_dataset = dataset.remove_columns(['group_id', 'image_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ec237b-3a12-439e-9cd7-c206346c2713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_name': 'voltage',\n",
       " 'entity_value': '130.0 volt',\n",
       " 'image': './processed/train/61dXfeoSP7L.jpg'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c567d50-551f-4f06-8f90-2258d79b3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22a6c3bc-83d5-4d6b-b9e5-1de3a857bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataCollator:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "        self.image_token_id = processor.tokenizer.additional_special_tokens_ids[\n",
    "            processor.tokenizer.additional_special_tokens.index(\"<image>\")\n",
    "        ]\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        global images_dict\n",
    "        texts = []\n",
    "        images = []\n",
    "        for example in examples:\n",
    "            image = images_dict[example[\"image\"]]\n",
    "            question = f'What is the {example[\"entity_name\"].replace(\"_\", \" \")} of the product?'\n",
    "            answer = example['entity_value']\n",
    "            system_prompt = f'''\n",
    "            1. Report the value and unit exactly as they appear in the image.\n",
    "            2. If the feature is not visible respond with an empty string.\n",
    "            3. Provide your answer in the format: \"value unit\" (e.g., \"500 gram\" or \"2.5 inch\").\n",
    "            4. Acceptable units: {entity_unit_map[example[\"entity_name\"]]}\n",
    "            '''\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": system_prompt},\n",
    "                        {\"type\": \"image\"},\n",
    "                        {\"type\": \"text\", \"text\": question}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": answer}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "            text = processor.apply_chat_template(messages, add_generation_prompt=False)\n",
    "            texts.append(text.strip())\n",
    "            images.append([image])\n",
    "\n",
    "        batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.image_token_id\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = MyDataCollator(processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8025932e-e418-4b45-9920-3e12d5535064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1, \n",
    "    per_device_train_batch_size=10,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.005,\n",
    "    logging_steps=25,\n",
    "    output_dir=\"./models/trained/train\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    save_total_limit=1,  # Keep only the latest checkpoint\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a93cb871-44c8-42cc-a912-015083177962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1625' max='1625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1625/1625 10:16:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1625, training_loss=0.01889698184453524, metrics={'train_runtime': 36983.5859, 'train_samples_per_second': 3.515, 'train_steps_per_second': 0.044, 'total_flos': 1.3418624332161572e+18, 'train_loss': 0.01889698184453524, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c940599-d909-4690-b358-994d1e868008",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e33489-7ee6-4cc6-a522-a2e9c7dd00fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
